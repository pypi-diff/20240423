# Comparing `tmp/label_convert-0.0.8-py3-none-any.whl.zip` & `tmp/label_convert-0.0.9-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,17 +1,17 @@
-Zip file size: 24081 bytes, number of entries: 15
--rw-r--r--  2.0 unx       74 b- defN 24-Mar-28 14:10 label_convert/__init__.py
--rw-r--r--  2.0 unx     5303 b- defN 24-Mar-28 14:10 label_convert/coco_to_labelImg.py
--rw-r--r--  2.0 unx     3296 b- defN 24-Mar-28 14:10 label_convert/coco_visual.py
--rw-r--r--  2.0 unx     7214 b- defN 24-Mar-28 14:10 label_convert/darknet_to_coco.py
--rw-r--r--  2.0 unx     7069 b- defN 24-Mar-28 14:10 label_convert/labelImg_to_publaynet.py
--rw-r--r--  2.0 unx     5264 b- defN 24-Mar-28 14:10 label_convert/labelImg_to_yolov5.py
--rw-r--r--  2.0 unx     8412 b- defN 24-Mar-28 14:10 label_convert/labelme_to_coco.py
--rw-r--r--  2.0 unx     7902 b- defN 24-Mar-28 14:10 label_convert/yolov5_to_coco.py
--rw-r--r--  2.0 unx     7667 b- defN 24-Mar-28 14:10 label_convert/yolov5_yaml_to_coco.py
--rw-r--r--  2.0 unx    11356 b- defN 24-Mar-28 14:11 label_convert-0.0.8.dist-info/LICENSE
--rw-r--r--  2.0 unx     2634 b- defN 24-Mar-28 14:11 label_convert-0.0.8.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-28 14:11 label_convert-0.0.8.dist-info/WHEEL
--rw-r--r--  2.0 unx      461 b- defN 24-Mar-28 14:11 label_convert-0.0.8.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       14 b- defN 24-Mar-28 14:11 label_convert-0.0.8.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1320 b- defN 24-Mar-28 14:11 label_convert-0.0.8.dist-info/RECORD
-15 files, 68078 bytes uncompressed, 21869 bytes compressed:  67.9%
+Zip file size: 24312 bytes, number of entries: 15
+-rw-r--r--  2.0 unx       74 b- defN 24-Mar-30 07:53 label_convert/__init__.py
+-rw-r--r--  2.0 unx     5391 b- defN 24-Mar-30 07:53 label_convert/coco_to_labelImg.py
+-rw-r--r--  2.0 unx     7302 b- defN 24-Mar-30 07:53 label_convert/darknet_to_coco.py
+-rw-r--r--  2.0 unx     7193 b- defN 24-Mar-30 07:53 label_convert/labelImg_to_publaynet.py
+-rw-r--r--  2.0 unx     5352 b- defN 24-Mar-30 07:53 label_convert/labelImg_to_yolov5.py
+-rw-r--r--  2.0 unx     8524 b- defN 24-Mar-30 07:53 label_convert/labelme_to_coco.py
+-rw-r--r--  2.0 unx     3739 b- defN 24-Mar-30 07:53 label_convert/vis_coco.py
+-rw-r--r--  2.0 unx     8631 b- defN 24-Mar-30 07:53 label_convert/yolov5_to_coco.py
+-rw-r--r--  2.0 unx     8409 b- defN 24-Mar-30 07:53 label_convert/yolov5_yaml_to_coco.py
+-rw-r--r--  2.0 unx    11336 b- defN 24-Mar-30 07:53 label_convert-0.0.9.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1087 b- defN 24-Mar-30 07:53 label_convert-0.0.9.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Mar-30 07:53 label_convert-0.0.9.dist-info/WHEEL
+-rw-r--r--  2.0 unx      455 b- defN 24-Mar-30 07:53 label_convert-0.0.9.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       14 b- defN 24-Mar-30 07:53 label_convert-0.0.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1317 b- defN 24-Mar-30 07:53 label_convert-0.0.9.dist-info/RECORD
+15 files, 68916 bytes uncompressed, 22106 bytes compressed:  67.9%
```

## zipnote {}

```diff
@@ -1,46 +1,46 @@
 Filename: label_convert/__init__.py
 Comment: 
 
 Filename: label_convert/coco_to_labelImg.py
 Comment: 
 
-Filename: label_convert/coco_visual.py
-Comment: 
-
 Filename: label_convert/darknet_to_coco.py
 Comment: 
 
 Filename: label_convert/labelImg_to_publaynet.py
 Comment: 
 
 Filename: label_convert/labelImg_to_yolov5.py
 Comment: 
 
 Filename: label_convert/labelme_to_coco.py
 Comment: 
 
+Filename: label_convert/vis_coco.py
+Comment: 
+
 Filename: label_convert/yolov5_to_coco.py
 Comment: 
 
 Filename: label_convert/yolov5_yaml_to_coco.py
 Comment: 
 
-Filename: label_convert-0.0.8.dist-info/LICENSE
+Filename: label_convert-0.0.9.dist-info/LICENSE
 Comment: 
 
-Filename: label_convert-0.0.8.dist-info/METADATA
+Filename: label_convert-0.0.9.dist-info/METADATA
 Comment: 
 
-Filename: label_convert-0.0.8.dist-info/WHEEL
+Filename: label_convert-0.0.9.dist-info/WHEEL
 Comment: 
 
-Filename: label_convert-0.0.8.dist-info/entry_points.txt
+Filename: label_convert-0.0.9.dist-info/entry_points.txt
 Comment: 
 
-Filename: label_convert-0.0.8.dist-info/top_level.txt
+Filename: label_convert-0.0.9.dist-info/top_level.txt
 Comment: 
 
-Filename: label_convert-0.0.8.dist-info/RECORD
+Filename: label_convert-0.0.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## label_convert/coco_to_labelImg.py

```diff
@@ -11,14 +11,17 @@
 from tqdm import tqdm
 
 ValueType = Union[str, Path, None]
 
 
 class COCOTolabelImg:
     def __init__(self, data_dir: ValueType = None, save_dir: ValueType = None):
+        if data_dir is None:
+            raise ValueError("data_dir must not be None")
+
         self.data_dir = Path(data_dir)
         self.verify_exists(self.data_dir)
 
         anno_dir = self.data_dir / "annotations"
         self.verify_exists(anno_dir)
 
         self.train_json = anno_dir / "instances_train2017.json"
```

## label_convert/darknet_to_coco.py

```diff
@@ -16,14 +16,17 @@
 
 class DarknetToCOCO:
     def __init__(
         self,
         data_dir: ValueType = None,
         save_dir: ValueType = None,
     ):
+        if data_dir is None:
+            raise ValueError("data_dir must not be None")
+
         self.data_dir = Path(data_dir)
         self.verify_exists(self.data_dir)
 
         self.config_path = self.data_dir / "gen_config.data"
         self.config = self.load_cfg()
 
         if save_dir is None:
```

## label_convert/labelImg_to_publaynet.py

```diff
@@ -19,14 +19,17 @@
         self,
         data_dir: ValueType = None,
         save_dir: ValueType = None,
         val_ratio: float = 0.2,
         have_test: bool = True,
         test_ratio: float = 0.2,
     ):
+        if data_dir is None:
+            raise ValueError("data_dir must not be None")
+
         self.data_dir = Path(data_dir)
         self.verify_exists(data_dir)
 
         if save_dir is None:
             save_dir = self.data_dir.with_name(f"{self.data_dir.stem}_publaynet")
         self.save_dir = Path(save_dir)
 
@@ -128,15 +131,15 @@
             }
 
             res["images"].append(img_dict)
 
             label_path = img_path.with_name(f"{img_path.stem}.txt")
             try:
                 label_datas = self.read_txt(label_path)
-            except Exception as e:
+            except Exception:
                 print(f"{label_path} meets error.")
                 continue
 
             for label_id, label_data in enumerate(label_datas):
                 cls_idx, x, y, w, h = label_data.split(" ")
 
                 left_x, left_y, box_w, box_h = self.xywh_to_x0y0wh(
@@ -200,22 +203,23 @@
     @staticmethod
     def mkdir(dir_path: Union[Path, str]) -> None:
         Path(dir_path).mkdir(parents=True, exist_ok=True)
 
 
 def main():
     parser = argparse.ArgumentParser()
-    parser.add_argument(
-        "--data_dir", type=str, required=True, help="The directory from labelImg."
-    )
+    parser.add_argument("--data_dir", type=str, default=None)
+    parser.add_argument("--save_dir", type=str, default=None)
     parser.add_argument("--val_ratio", type=float, default=0.2)
     parser.add_argument("--have_test", action="store_true", default=False)
     parser.add_argument("--test_ratio", type=float, default=0.2)
     args = parser.parse_args()
 
-    converter = LabelImgToPubLayNet(args.val_ratio, args.have_test, args.test_ratio)
-    converter(args.data_dir)
+    converter = LabelImgToPubLayNet(
+        args.data_dir, args.save_dir, args.val_ratio, args.have_test, args.test_ratio
+    )
+    converter()
     print(f"Successfully output to the {args.out_dir}")
 
 
 if __name__ == "__main__":
     main()
```

## label_convert/labelImg_to_yolov5.py

```diff
@@ -18,14 +18,17 @@
         self,
         data_dir: ValueType = None,
         save_dir: ValueType = None,
         val_ratio: float = 0.2,
         have_test: bool = False,
         test_ratio: float = 0.2,
     ):
+        if data_dir is None:
+            raise ValueError("data_dir must not be None")
+
         self.data_dir = Path(data_dir)
         self.verify_exists(self.data_dir)
 
         if save_dir is None:
             save_dir = self.data_dir.parent / f"{self.data_dir.name}_yolov5"
         self.save_dir = Path(save_dir)
```

## label_convert/labelme_to_coco.py

```diff
@@ -3,33 +3,35 @@
 # @Contact: liekkaskono@163.com
 import argparse
 import json
 import random
 import shutil
 import time
 from pathlib import Path
-from typing import List, Optional, Union
+from typing import Union
 
 import numpy as np
 from tqdm import tqdm
 
 ValueType = Union[str, Path, None]
 
 
 class LabelmeToCOCO:
-
     def __init__(
         self,
         data_dir: ValueType = None,
         save_dir: ValueType = None,
         val_ratio: float = 0.2,
         have_test: bool = False,
         test_ratio: float = 0.2,
     ):
+        if data_dir is None:
+            raise ValueError("data_dir must not be None")
         self.data_dir = Path(data_dir)
+        self.verify_exists(self.data_dir)
 
         self.val_ratio = val_ratio
         self.test_ratio = test_ratio
         self.have_test = have_test
 
         self.verify_exists(self.data_dir)
```

## label_convert/yolov5_to_coco.py

```diff
@@ -6,23 +6,26 @@
 import shutil
 import time
 import warnings
 from pathlib import Path
 from typing import List, Tuple, Union
 
 import cv2
+import numpy as np
 from tqdm import tqdm
 
 ValueType = Union[str, Path, None]
 
 
 class YOLOV5ToCOCO:
     def __init__(self, data_dir: ValueType = None, save_dir: ValueType = None):
+        if data_dir is None:
+            raise ValueError("data_dir must not be None")
         self.data_dir = Path(data_dir)
-
+        self.verify_exists(self.data_dir)
         self.verify_exists(self.data_dir / "images")
         self.verify_exists(self.data_dir / "labels")
 
         if save_dir is None:
             save_dir = self.data_dir.parent / f"{Path(self.data_dir).name}_coco"
         self.save_dir = save_dir
         self.mkdir(self.save_dir)
@@ -100,15 +103,19 @@
     def convert(self, img_list, save_img_dir, mode):
         images, annotations = [], []
         for img_id, img_path in enumerate(tqdm(img_list, desc=mode), 1):
             image_dict = self.get_image_info(img_path, img_id, save_img_dir)
             images.append(image_dict)
 
             label_path = self.data_dir / "labels" / f"{Path(img_path).stem}.txt"
-            annotation = self.get_annotation(
+            if not label_path.exists():
+                warnings.warn(f"{label_path} not exists. Skip")
+                continue
+
+            annotation = self.read_annotation(
                 label_path, img_id, image_dict["height"], image_dict["width"]
             )
             annotations.extend(annotation)
 
         json_data = {
             "info": self.info,
             "images": images,
@@ -118,16 +125,14 @@
             "categories": self.categories,
         }
         return json_data
 
     def get_image_info(self, img_path, img_id, save_img_dir):
         img_path = Path(img_path)
         if self.data_dir.as_posix() not in img_path.as_posix():
-            # relative path (relative to the data_dir)
-            # e.g. images/images(3).jpg
             img_path = self.data_dir / img_path
 
         self.verify_exists(img_path)
 
         new_img_name = f"{img_id:012d}.jpg"
         save_img_path = save_img_dir / new_img_name
         img_src = cv2.imread(str(img_path))
@@ -142,61 +147,37 @@
             "file_name": new_img_name,
             "id": img_id,
             "height": height,
             "width": width,
         }
         return image_info
 
-    def get_annotation(self, label_path: Path, img_id, height, width):
-        def get_box_info(vertex_info, height, width):
-            cx, cy, w, h = [float(i) for i in vertex_info]
-
-            cx = cx * width
-            cy = cy * height
-            box_w = w * width
-            box_h = h * height
-
-            # left top
-            x0 = max(cx - box_w / 2, 0)
-            y0 = max(cy - box_h / 2, 0)
-
-            # right bottom
-            x1 = min(x0 + box_w, width)
-            y1 = min(y0 + box_h, height)
-
-            segmentation = [[x0, y0, x1, y0, x1, y1, x0, y1]]
-            bbox = [x0, y0, box_w, box_h]
-            area = box_w * box_h
-            return segmentation, bbox, area
-
-        if not label_path.exists():
-            annotation = [
-                {
-                    "segmentation": [],
-                    "area": 0,
-                    "iscrowd": 0,
-                    "image_id": img_id,
-                    "bbox": [],
-                    "category_id": -1,
-                    "id": self.annotation_id,
-                }
-            ]
-            self.annotation_id += 1
-            return annotation
-
+    def read_annotation(self, label_path: Path, img_id, height, width):
         annotation = []
         label_list = self.read_txt(str(label_path))
         for i, one_line in enumerate(label_list):
             label_info = one_line.split(" ")
             if len(label_info) < 5:
                 warnings.warn(f"The {i+1} line of the {label_path} has been corrupted.")
                 continue
 
             category_id, vertex_info = label_info[0], label_info[1:]
-            segmentation, bbox, area = get_box_info(vertex_info, height, width)
+            point_nums = len(vertex_info)
+            if point_nums == 4:
+                segmentation, bbox, area = self.get_annotation_from_rectangle(
+                    vertex_info, height, width
+                )
+            elif point_nums > 4:
+                segmentation, bbox, area = self.get_annotation_from_poly(
+                    vertex_info, height, width
+                )
+            else:
+                warnings.warn("The nums of points are less than 4. Skip")
+                continue
+
             annotation.append(
                 {
                     "segmentation": segmentation,
                     "area": area,
                     "iscrowd": 0,
                     "image_id": img_id,
                     "bbox": bbox,
@@ -204,14 +185,52 @@
                     "id": self.annotation_id,
                 }
             )
             self.annotation_id += 1
         return annotation
 
     @staticmethod
+    def get_annotation_from_rectangle(vertex_info, height, width):
+        cx, cy, w, h = [float(i) for i in vertex_info]
+
+        cx = cx * width
+        cy = cy * height
+        box_w = w * width
+        box_h = h * height
+
+        x0 = max(cx - box_w / 2, 0)
+        y0 = max(cy - box_h / 2, 0)
+        x1 = min(x0 + box_w, width)
+        y1 = min(y0 + box_h, height)
+
+        segmentation = [[x0, y0, x1, y0, x1, y1, x0, y1]]
+        bbox = [x0, y0, box_w, box_h]
+        area = box_w * box_h
+        return segmentation, bbox, area
+
+    @staticmethod
+    def get_annotation_from_poly(vertex_info: List[str], height, width):
+        points = np.array(vertex_info).astype(np.float64).reshape(-1, 2)
+
+        new_points = np.copy(points)
+        new_points[:, 0] = points[:, 0] * width
+        new_points[:, 1] = points[:, 1] * height
+
+        segmentation = new_points.tolist()
+
+        x0, y0 = np.min(new_points, axis=0)
+        x1, y1 = np.max(new_points, axis=0)
+        box_w = x1 - x0
+        box_h = y1 - y0
+        bbox = [x0, y0, box_w, box_h]
+
+        area = box_w * box_h
+        return segmentation, bbox, area
+
+    @staticmethod
     def read_txt(txt_path):
         with open(str(txt_path), "r", encoding="utf-8") as f:
             data = list(map(lambda x: x.rstrip("\n"), f))
         return data
 
     @staticmethod
     def mkdir(dir_path):
@@ -227,15 +246,18 @@
         with open(json_path, "w", encoding="utf-8") as f:
             json.dump(content, f, ensure_ascii=False)
 
 
 def main():
     parser = argparse.ArgumentParser("Datasets converter from YOLOV5 to COCO")
     parser.add_argument(
-        "--data_dir", type=str, default="dataset/YOLOV5", help="Dataset root path"
+        "--data_dir",
+        type=str,
+        default="tests/test_files/yolov5_dataset",
+        help="Dataset root path",
     )
     parser.add_argument(
         "--mode_list", type=str, default="train,val", help="generate which mode"
     )
     args = parser.parse_args()
 
     converter = YOLOV5ToCOCO(args.data_dir)
```

## label_convert/yolov5_yaml_to_coco.py

```diff
@@ -1,18 +1,20 @@
 # -*- encoding: utf-8 -*-
 # @Author: SWHL
 # @Contact: liekkaskono@163.com
 import argparse
 import json
 import shutil
 import time
+import warnings
 from pathlib import Path
-from typing import Union
+from typing import List, Union
 
 import cv2
+import numpy as np
 import yaml
 from tqdm import tqdm
 
 
 class YOLOV5CfgToCOCO:
     def __init__(
         self,
@@ -22,17 +24,21 @@
         if yaml_path is None:
             raise ValueError("yaml_path must not be empty!")
 
         self.verify_exists(yaml_path)
         with open(yaml_path, "r", encoding="utf-8") as f:
             self.cfg = yaml.safe_load(f)
 
-        self.data_dir = Path(self.cfg.get("path"))
-        self.train_dir = self.data_dir / self.cfg.get("train")[0]
-        self.val_dir = self.data_dir / self.cfg.get("val")[0]
+        data_dir = self.cfg.get("path", None)
+        if data_dir is None:
+            data_dir = ""
+
+        self.data_dir = Path(data_dir)
+        self.train_dir = self.data_dir / self.cfg.get("train")
+        self.val_dir = self.data_dir / self.cfg.get("val")
 
         nc = self.cfg.get("nc")
         self.names = self.cfg.get("names")
         assert nc == len(self.names)
 
         if save_dir is None:
             save_dir = self.data_dir.parent / f"{self.data_dir.name}_coco"
@@ -92,27 +98,14 @@
                 "url": "https://github.com/RapidAI/LabelConvert/LICENSE",
             }
         ]
 
     def get_img_list(self, data_dir: Path):
         return list(data_dir.rglob("*.*"))
 
-    def _get_data_dir(self, mode):
-        data_dir = self.cfg.get(mode)
-        if data_dir:
-            if isinstance(data_dir, str):
-                full_path = [str(self.data_dir / data_dir)]
-            elif isinstance(data_dir, list):
-                full_path = [str(self.data_dir / one_dir) for one_dir in data_dir]
-            else:
-                raise TypeError(f"{data_dir} is not str or list.")
-        else:
-            raise ValueError(f"{mode} dir is not in the yaml.")
-        return full_path
-
     def _get_category(self):
         categories = []
         for i, category in enumerate(self.names, start=1):
             categories.append(
                 {
                     "supercategory": category,
                     "id": i,
@@ -145,42 +138,58 @@
                     "width": width,
                 }
             )
 
             label_name = f"{img_path.stem}.txt"
             label_path = self.data_dir / "labels" / img_path.parent.name / label_name
             if not label_path.exists():
-                raise FileNotFoundError(f"{label_path} not exists")
+                warnings.warn(f"{label_path} not exists. Skip")
+                continue
 
             new_anno = self.read_annotation(label_path, img_id, height, width)
             if len(new_anno) <= 0:
-                raise ValueError(f"{label_path} is empty")
+                warnings.warn(f"{label_path} is empty. Skip")
+                continue
             annotations.extend(new_anno)
 
         json_data = {
             "info": self.info,
             "images": images,
             "licenses": self.licenses,
             "type": self.type,
             "annotations": annotations,
             "categories": self.categories,
         }
         with open(target_json, "w", encoding="utf-8") as f:
             json.dump(json_data, f, ensure_ascii=False)
 
-    def read_annotation(self, txt_file, img_id, height, width):
+    def read_annotation(self, label_path, img_id, height, width):
         annotation = []
-        all_info = self.read_txt(txt_file)
+        all_info = self.read_txt(label_path)
         for label_info in all_info:
             label_info = label_info.split(" ")
-            if len(label_info) < 5:
+            label_len = len(label_info)
+            if label_len < 5:
                 continue
 
             category_id, vertex_info = label_info[0], label_info[1:]
-            segmentation, bbox, area = self._get_annotation(vertex_info, height, width)
+
+            point_nums = len(vertex_info)
+            if point_nums == 4:
+                segmentation, bbox, area = self.get_annotation_from_rectangle(
+                    vertex_info, height, width
+                )
+            elif point_nums > 4:
+                segmentation, bbox, area = self.get_annotation_from_poly(
+                    vertex_info, height, width
+                )
+            else:
+                warnings.warn("The nums of points are less than 4. Skip")
+                continue
+
             annotation.append(
                 {
                     "segmentation": segmentation,
                     "area": area,
                     "iscrowd": 0,
                     "image_id": img_id,
                     "bbox": bbox,
@@ -188,15 +197,15 @@
                     "id": self.annotation_id,
                 }
             )
             self.annotation_id += 1
         return annotation
 
     @staticmethod
-    def _get_annotation(vertex_info, height, width):
+    def get_annotation_from_rectangle(vertex_info, height, width):
         cx, cy, w, h = [float(i) for i in vertex_info]
 
         cx = cx * width
         cy = cy * height
         box_w = w * width
         box_h = h * height
 
@@ -207,14 +216,33 @@
 
         segmentation = [[x0, y0, x1, y0, x1, y1, x0, y1]]
         bbox = [x0, y0, box_w, box_h]
         area = box_w * box_h
         return segmentation, bbox, area
 
     @staticmethod
+    def get_annotation_from_poly(vertex_info: List[str], height, width):
+        points = np.array(vertex_info).astype(np.float64).reshape(-1, 2)
+
+        new_points = np.copy(points)
+        new_points[:, 0] = points[:, 0] * width
+        new_points[:, 1] = points[:, 1] * height
+
+        segmentation = new_points.tolist()
+
+        x0, y0 = np.min(new_points, axis=0)
+        x1, y1 = np.max(new_points, axis=0)
+        box_w = x1 - x0
+        box_h = y1 - y0
+        bbox = [x0, y0, box_w, box_h]
+
+        area = box_w * box_h
+        return segmentation, bbox, area
+
+    @staticmethod
     def read_txt(txt_path):
         with open(str(txt_path), "r", encoding="utf-8") as f:
             data = list(map(lambda x: x.rstrip("\n"), f))
         return data
 
     @staticmethod
     def mkdir(dir_path):
@@ -228,15 +256,15 @@
 
 
 def main():
     parser = argparse.ArgumentParser("Datasets converter from YOLOV5 to COCO")
     parser.add_argument(
         "--yaml_path",
         type=str,
-        default="dataset/YOLOV5_yaml/sample.yaml",
+        default="tests/test_files/crack.v1i.yolov7pytorch/data.yaml",
         help="Dataset cfg file",
     )
     args = parser.parse_args()
 
     converter = YOLOV5CfgToCOCO(args.yaml_path)
     converter()
```

## Comparing `label_convert/coco_visual.py` & `label_convert/vis_coco.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,102 +1,124 @@
 # -*- encoding: utf-8 -*-
 # @Author: SWHL
 # @Contact: liekkaskono@163.com
 import argparse
 import json
-import os
 import platform
 import random
+from pathlib import Path
 
 import cv2
+import numpy as np
 
 
 class VisCOCO:
     def __init__(
         self,
     ):
-        pass
+        self.font_size = 0.7
 
-    def __call__(self, num_image, json_path, img_path):
+    def __call__(self, img_id: int, json_path, img_path):
         with open(json_path, "r", encoding="utf-8") as annos:
-            annotation_json = json.load(annos)
+            anno_dict = json.load(annos)
 
-        print("The annotation_json num_key is:", len(annotation_json))
-        print("The annotation_json key is:", annotation_json.keys())
-        print("The annotation_json num_images is:", len(annotation_json["images"]))
+        anno_imgs = anno_dict.get("images", None)
+        if anno_imgs is None:
+            raise ValueError(f"The images of {json_path} cannot be empty.")
 
-        categories = annotation_json["categories"]
+        print("The anno_dict num_key is:", len(anno_dict))
+        print("The anno_dict key is:", anno_dict.keys())
+        print("The anno_dict num_images is:", len(anno_imgs))
+
+        categories = anno_dict["categories"]
         categories_dict = {c["id"]: c["name"] for c in categories}
+
         class_nums = len(categories_dict.keys())
         color = [
             (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
             for _ in range(class_nums)
         ]
 
-        image_name = annotation_json["images"][num_image - 1]["file_name"]
-        img_id = annotation_json["images"][num_image - 1]["id"]
-        image_path = os.path.join(img_path, str(image_name).zfill(5))
-        image = cv2.imread(image_path, 1)
+        img_info = anno_dict["images"][img_id - 1]
+        img_name = img_info.get("file_name")
 
-        annotations = annotation_json["annotations"]
+        img_full_path = Path(img_path) / img_name
+        image = cv2.imread(str(img_full_path))
+
+        annotations = anno_dict["annotations"]
         num_bbox = 0
+        img_id = img_info.get("id")
         for anno in annotations:
-            if anno["image_id"] == img_id:
-                num_bbox = num_bbox + 1
+            if anno["image_id"] != img_id:
+                continue
+
+            num_bbox += 1
 
-                class_id = anno["category_id"]
-                class_name = categories_dict[class_id]
-                class_color = color[class_id - 1]
-
-                x, y, w, h = list(map(int, anno["bbox"]))
-                cv2.rectangle(
-                    image, (int(x), int(y)), (int(x + w), int(y + h)), class_color, 2
-                )
-
-                font_size = 0.7
-                txt_size = cv2.getTextSize(
-                    class_name, cv2.FONT_HERSHEY_SIMPLEX, font_size, 1
-                )[0]
-                cv2.rectangle(
-                    image,
-                    (x, y + 1),
-                    (x + txt_size[0] + 10, y - int(2 * txt_size[1])),
-                    class_color,
-                    -1,
-                )
-                cv2.putText(
-                    image,
-                    class_name,
-                    (x + 5, y - 5),
-                    cv2.FONT_HERSHEY_SIMPLEX,
-                    font_size,
-                    (255, 255, 255),
-                    1,
-                )
+            class_id = anno["category_id"]
+            class_name = categories_dict[class_id]
+            class_color = color[class_id - 1]
+
+            # plot sgmentations
+            segs = anno.get("segmentation", None)
+            if segs is not None:
+                segs = np.array(segs).reshape(-1, 2)
+                cv2.polylines(image, np.int32([segs]), 2, class_color)
+
+            # plot rectangle
+            x, y, w, h = [round(v) for v in anno["bbox"]]
+            cv2.rectangle(
+                image, (int(x), int(y)), (int(x + w), int(y + h)), class_color, 2
+            )
+
+            txt_size = cv2.getTextSize(
+                class_name, cv2.FONT_HERSHEY_SIMPLEX, self.font_size, 1
+            )[0]
+            cv2.rectangle(
+                image,
+                (x, y + 1),
+                (x + txt_size[0] + 5, y - int(1.5 * txt_size[1])),
+                class_color,
+                -1,
+            )
+            cv2.putText(
+                image,
+                class_name,
+                (x + 5, y - 5),
+                cv2.FONT_HERSHEY_SIMPLEX,
+                self.font_size,
+                (255, 255, 255),
+                1,
+            )
 
         print("The unm_bbox of the display image is:", num_bbox)
 
         cur_os = platform.system()
         if cur_os == "Windows":
-            cv2.namedWindow(image_name, 0)
-            cv2.resizeWindow(image_name, 1000, 1000)
-            cv2.imshow(image_name, image)
+            cv2.namedWindow(img_name, 0)
+            cv2.resizeWindow(img_name, 1000, 1000)
+            cv2.imshow(img_name, image)
             cv2.waitKey(0)
         else:
-            save_path = f"visul_{num_image}.jpg"
+            save_path = f"vis_{Path(img_name).stem}.jpg"
             cv2.imwrite(save_path, image)
             print(f"The {save_path} has been saved the current director.")
 
 
 def main():
     parser = argparse.ArgumentParser()
-    parser.add_argument("--vis_num", type=int, default=1, help="visual which one")
-    parser.add_argument("--json_path", type=str, required=True)
-    parser.add_argument("--img_dir", type=str, required=True)
+    parser.add_argument("--img_id", type=int, default=1, help="visual which one")
+    parser.add_argument(
+        "--json_path",
+        type=str,
+        default="tests/test_files/yolov5_dataset_coco/annotations/instances_train2017.json",
+    )
+    parser.add_argument(
+        "--img_dir", type=str, default="tests/test_files/yolov5_dataset_coco/train2017"
+    )
     args = parser.parse_args()
 
     viser = VisCOCO()
-    viser(args.vis_num, args.json_path, args.img_dir)
+    viser(args.img_id, args.json_path, args.img_dir)
 
 
 if __name__ == "__main__":
     main()
```

## Comparing `label_convert-0.0.8.dist-info/LICENSE` & `label_convert-0.0.9.dist-info/LICENSE`

 * *Files 0% similar despite different names*

```diff
@@ -182,15 +182,15 @@
       replaced with your own identifying information. (Don't include
       the brackets!)  The text should be enclosed in the appropriate
       comment syntax for the file format. We also recommend that a
       file or class name and description of purpose be included on the
       same "printed page" as the copyright notice for easier
       identification within third-party archives.
 
-   Copyright [yyyy] [name of copyright owner]
+   Copyright 2024 RapidAI
 
    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at
 
        http://www.apache.org/licenses/LICENSE-2.0
```

## Comparing `label_convert-0.0.8.dist-info/RECORD` & `label_convert-0.0.9.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,15 +1,15 @@
 label_convert/__init__.py,sha256=m-UGKHJ-31qL7pBis4nfoFz5fzb-dXsiTLNqY-xpSoA,74
-label_convert/coco_to_labelImg.py,sha256=RkPJpE-xXeLeUXBzWqeOEouNd9NibrTOVubOUS3II04,5303
-label_convert/coco_visual.py,sha256=3jMk4eaUokIHjRvV_CFW23RYXZicUTCA2SAtKQyGwa0,3296
-label_convert/darknet_to_coco.py,sha256=BlSUku7ZSnfjNcqVOQkL006sgUyQAD8SNboVU_2sNNo,7214
-label_convert/labelImg_to_publaynet.py,sha256=ka8otxdhkTI2yKSoeJfFIRsQESMRwAcORdW-1gzDmTs,7069
-label_convert/labelImg_to_yolov5.py,sha256=kzHDoc9CxKJjaTJRGwSQ_Qt0KlQSQxff1V4vDA7Ehrw,5264
-label_convert/labelme_to_coco.py,sha256=3VnN7KCoujcAMRdWULHgaIJKjrRQvX1KaOlAvtcDAIs,8412
-label_convert/yolov5_to_coco.py,sha256=zEDD5JPEcDZXGlabE8fhgle5ymtCKJoZHrwfKlALFp0,7902
-label_convert/yolov5_yaml_to_coco.py,sha256=MhyYjy95PwNr9Q0RvYiwkuKV6c6mKDCZay-YG21i8BU,7667
-label_convert-0.0.8.dist-info/LICENSE,sha256=QwcOLU5TJoTeUhuIXzhdCEEDDvorGiC6-3YTOl4TecE,11356
-label_convert-0.0.8.dist-info/METADATA,sha256=tqo1QUw49CZB70rjOuKGfxEaDTwHzvlB09gmDp-qAGg,2634
-label_convert-0.0.8.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-label_convert-0.0.8.dist-info/entry_points.txt,sha256=mDBGzA2Ao4v-89O1L0dKkz5BqeUj4m4bTKWxPkkuSM4,461
-label_convert-0.0.8.dist-info/top_level.txt,sha256=19hCY1mpryjfbkF4MbzbCTj3Mzsdh4pt3rkx1yYbspo,14
-label_convert-0.0.8.dist-info/RECORD,,
+label_convert/coco_to_labelImg.py,sha256=KtBLHxBmdgA4z-MYxAWgjFNlQEh9c8kSb0wvY_-pIK8,5391
+label_convert/darknet_to_coco.py,sha256=ihzz5LJea631z3Wn9_9501Ha4CTelKgZ-24X16YPE3s,7302
+label_convert/labelImg_to_publaynet.py,sha256=_dIMT_1zaCEuSTHCJYv6FlLHvlSDHhhxddaNRUXINgM,7193
+label_convert/labelImg_to_yolov5.py,sha256=8SdeueExPhXZREA9pNWVdcgphFrUAMC4TykVfpzqanU,5352
+label_convert/labelme_to_coco.py,sha256=IkFGImQj82zXnNWHBzYVWxtJJnGIKHNH9ESUmtXPJNg,8524
+label_convert/vis_coco.py,sha256=fqBnN6dodXIny5trzTW5Y4ANfasQo8Vd8Eg7py-DlF0,3739
+label_convert/yolov5_to_coco.py,sha256=fNbqtn7f0mcXLp-wR4D2K_v1mkjSMDUiObL7D48-fbY,8631
+label_convert/yolov5_yaml_to_coco.py,sha256=2QMqZ1TuKvy9sihPb952DC-EuMwStwAUZfgkUqnVWNQ,8409
+label_convert-0.0.9.dist-info/LICENSE,sha256=it8xkwp-gjqyrpU_P9H7V6a4v_Ws0nkOQWifs03Gmz4,11336
+label_convert-0.0.9.dist-info/METADATA,sha256=rR1lKQKBojyziQzNa2gRiWGBxnbrjW66Z7x9JB_giKg,1087
+label_convert-0.0.9.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
+label_convert-0.0.9.dist-info/entry_points.txt,sha256=k6L9OvEUELEKrcqc6dGkD7phTm0L-GwO065AOZ_gVms,455
+label_convert-0.0.9.dist-info/top_level.txt,sha256=19hCY1mpryjfbkF4MbzbCTj3Mzsdh4pt3rkx1yYbspo,14
+label_convert-0.0.9.dist-info/RECORD,,
```

